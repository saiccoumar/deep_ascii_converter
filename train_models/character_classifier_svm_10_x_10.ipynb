{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "import joblib\n",
    "\n",
    "from collections import Counter\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "height, width = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2542, 4: 274, 90: 267, 62: 266, 33: 265, 49: 263, 64: 257, 29: 257, 59: 255, 72: 255, 77: 252, 79: 252, 9: 251, 17: 251, 56: 250, 66: 250, 91: 250, 18: 249, 11: 248, 81: 248, 44: 247, 71: 247, 75: 247, 38: 247, 51: 247, 45: 246, 35: 246, 3: 245, 28: 244, 25: 242, 26: 242, 20: 242, 40: 241, 63: 241, 41: 240, 76: 240, 61: 240, 73: 239, 1: 238, 86: 238, 23: 238, 8: 238, 78: 238, 89: 238, 31: 237, 83: 237, 5: 237, 65: 236, 15: 236, 57: 236, 74: 236, 22: 236, 54: 235, 24: 235, 43: 235, 42: 234, 95: 234, 67: 233, 58: 233, 92: 233, 12: 232, 30: 230, 80: 230, 34: 230, 21: 230, 10: 229, 46: 229, 37: 229, 52: 228, 19: 228, 48: 228, 69: 228, 82: 228, 36: 226, 50: 226, 85: 226, 60: 226, 53: 225, 27: 225, 68: 225, 32: 224, 84: 223, 70: 223, 13: 223, 94: 223, 2: 222, 7: 221, 16: 221, 14: 219, 39: 217, 6: 214, 93: 211, 47: 210, 55: 209, 88: 204, 87: 202})\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(f\"../archive/ascii_character_classification_{height}_x_{width}.csv\", header=0).sample(frac=.05)\n",
    "\n",
    "label_counts = Counter(data.iloc[:, 0])\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:].astype(\"float64\")   # Features are all columns except the first one\n",
    "y = data.iloc[:, 0].astype(\"float64\")     # Labels are the first column\n",
    "# Initialize the oversampler\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "# Optionally, if you want to convert them back to pandas DataFrames:\n",
    "train_data = pd.concat([y_train, X_train], axis=1)\n",
    "test_data = pd.concat([y_test, X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/svm_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "joblib.dump(clf, '../artifacts/svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Shape: (5000, 100)\n",
      "Train Accuracy: 94.8000%\n",
      "Test Accuracy: 93.8200%\n",
      "F1 Score: 92.9271%\n",
      "Recall: 93.8200%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"test Shape:\", X_test.shape)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy*100:.4f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.4f}%\")\n",
    "print(f\"F1 Score: {f1*100:.4f}%\")\n",
    "print(f\"Recall: {recall*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for image in images:\n",
    "        image_reshaped = image.reshape((height, width))\n",
    "        features = hog(image_reshaped, pixels_per_cell=(2, 2), cells_per_block=(1, 1), feature_vector=True)\n",
    "        hog_features.append(features)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "X_hog = extract_hog_features(np.array(X))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_hog, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/svm_model_hog_10_x_10.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "joblib.dump(clf, '../artifacts/svm_model_hog_10_x_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Shape: (5000, 225)\n",
      "Train Accuracy: 96.9200%\n",
      "Test Accuracy: 94.4600%\n",
      "F1 Score: 93.5780%\n",
      "Recall: 94.4600%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"test Shape:\", X_test.shape)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy*100:.4f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.4f}%\")\n",
    "print(f\"F1 Score: {f1*100:.4f}%\")\n",
    "print(f\"Recall: {recall*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_features = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_reshaped = image.reshape((height, width)).astype(np.uint8)\n",
    "        keypoints, descriptors = sift.detectAndCompute(image_reshaped, None)\n",
    "        \n",
    "        # If no keypoints are found, use a zero array of the same length as a typical descriptor\n",
    "        if descriptors is None:\n",
    "            descriptors = np.zeros((1, sift.descriptorSize()), dtype=np.float32)\n",
    "        \n",
    "        # Flatten descriptors and use them as features\n",
    "        features = descriptors.flatten()\n",
    "        sift_features.append(features)\n",
    "    \n",
    "    return np.array(sift_features)\n",
    "\n",
    "# Extract SIFT features\n",
    "X_sift = extract_sift_features(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sift = extract_sift_features(np.array(X))\n",
    "\n",
    "# Since the number of features might vary, we need to ensure consistent feature vector size\n",
    "# Here, we'll pad with zeros to the maximum descriptor length found\n",
    "max_len = max(len(f) for f in X_sift)\n",
    "X_sift = np.array([np.pad(f, (0, max_len - len(f)), 'constant') for f in X_sift])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sift, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/svm_model_sift_10_x_10.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "joblib.dump(clf, '../artifacts/svm_model_sift_10_x_10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Shape: (5000, 128)\n",
      "Train Accuracy: 10.0300%\n",
      "Test Accuracy: 10.7200%\n",
      "F1 Score: 2.0758%\n",
      "Recall: 10.7200%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"test Shape:\", X_test.shape)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy*100:.4f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.4f}%\")\n",
    "print(f\"F1 Score: {f1*100:.4f}%\")\n",
    "print(f\"Recall: {recall*100:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
